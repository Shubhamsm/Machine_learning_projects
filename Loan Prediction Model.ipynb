{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USED**\n",
    "libraries: Sklearn Numpy Pandas Seaborn  Scipy\n",
    "\n",
    "**what TODO**\n",
    "fill the values using backward 'bfill' method for numerical columns , and most frequent value for categorical columns (simple techniques)\n",
    "\n",
    "4 different models to train your data, so we can compare between them\n",
    "    a) logistic regression\n",
    "    b) KNeighborsClassifier\n",
    "    C) SVC\n",
    "    d) DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\n",
    "df.shape\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will change the type of Credit_History to object becaues we can see that it is 1 or 0\n",
    "df['Credit_History'] = df['Credit_History'].astype('O')\n",
    "\n",
    "# we will drop ID because it's not important for our model and it will just mislead the model\n",
    "df.drop('Loan_ID', axis=1, inplace=True)\n",
    "\n",
    "#checking Duplicate Rows\n",
    "df.duplicated().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the target percentage\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(df['Loan_Status']);\n",
    "\n",
    "print('The percentage of Y class : %.2f' % (df['Loan_Status'].value_counts()[0] / len(df)))\n",
    "print('The percentage of N class : %.2f' % (df['Loan_Status'].value_counts()[1] / len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look deeper in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit_History\n",
    "\n",
    "grid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\n",
    "grid.map(sns.countplot, 'Credit_History');\n",
    "\n",
    "# we didn't give a loan for most people who got Credit History = 0\n",
    "# but we did give a loan for most of people who got Credit History = 1\n",
    "# so we can say if you got Credit History = 1 , you will have better chance to get a loan\n",
    "\n",
    "# important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "\n",
    "grid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\n",
    "grid.map(sns.countplot, 'Gender');\n",
    "\n",
    "# most males got loan and most females got one too so (No pattern)\n",
    "\n",
    "# i think it's not so important feature, we will see later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Married\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x='Married', hue='Loan_Status', data=df);\n",
    "\n",
    "# most people who get married did get a loan\n",
    "# if you'r married then you have better chance to get a loan :)\n",
    "# good feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependents\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x='Dependents', hue='Loan_Status', data=df);\n",
    "\n",
    "# first if Dependents = 0 , we got higher chance to get a loan ((very hight chance))\n",
    "# good feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education\n",
    "\n",
    "grid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\n",
    "grid.map(sns.countplot, 'Education');\n",
    "\n",
    "# If you are graduated or not, you will get almost the same chance to get a loan (No pattern)\n",
    "# Here you can see that most people did graduated, and most of them got a loan\n",
    "# on the other hand, most of people who did't graduate also got a loan, but with less percentage from people who graduated\n",
    "\n",
    "# not important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self_Employed\n",
    "\n",
    "grid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\n",
    "grid.map(sns.countplot, 'Self_Employed');\n",
    "\n",
    "# No pattern (same as Education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property_Area\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x='Property_Area', hue='Loan_Status', data=df);\n",
    "\n",
    "# We can say, Semiurban Property_Area got more than 50% chance to get a loan\n",
    "\n",
    "# good feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ApplicantIncome\n",
    "\n",
    "plt.scatter(df['ApplicantIncome'], df['Loan_Status']);\n",
    "\n",
    "# No pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numerical data\n",
    "\n",
    "df.groupby('Loan_Status').median() # median because Not affected with outliers\n",
    "\n",
    "# we can see that when we got low median in CoapplicantInocme we got Loan_Status = N\n",
    "\n",
    "# CoapplicantInocme is a good feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple process for the data\n",
    "here i am just going to use a simple techniques to handle the missing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will separate the numerical columns from the categorical\n",
    "\n",
    "cat_data = []\n",
    "num_data = []\n",
    "\n",
    "for i,c in enumerate(df.dtypes):\n",
    "    if c == object:\n",
    "        cat_data.append(df.iloc[:, i])\n",
    "    else :\n",
    "        num_data.append(df.iloc[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = pd.DataFrame(cat_data).transpose()\n",
    "num_data = pd.DataFrame(num_data).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_data\n",
    "# If you want to fill every column with its own most frequent value you can use\n",
    "\n",
    "cat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "cat_data.isnull().sum().any() # no more missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_data\n",
    "# fill every missing value with their previous value in the same column\n",
    "\n",
    "num_data.fillna(method='bfill', inplace=True)\n",
    "num_data.isnull().sum().any() # no more missing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAbel Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  \n",
    "le = LabelEncoder()\n",
    "cat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the target column\n",
    "\n",
    "target_values = {'Y': 0 , 'N' : 1}\n",
    "\n",
    "target = cat_data['Loan_Status']\n",
    "cat_data.drop('Loan_Status', axis=1, inplace=True)\n",
    "\n",
    "target = target.map(target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform other columns\n",
    "\n",
    "for i in cat_data:\n",
    "    cat_data[i] = le.fit_transform(cat_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cat_data, num_data, target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([cat_data, num_data], axis=1)\n",
    "y = target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use StratifiedShuffleSplit to split the data Taking into consideration that we will get the same ratio on the target column\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train, test in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "    \n",
    "print('X_train shape', X_train.shape)\n",
    "print('y_train shape', y_train.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "print('y_test shape', y_test.shape)\n",
    "\n",
    "# almost same ratio\n",
    "print('\\nratio of target in y_train :',y_train.value_counts().values/ len(y_train))\n",
    "print('ratio of target in y_test :',y_test.value_counts().values/ len(y_test))\n",
    "print('ratio of target in original_data :',df['Loan_Status'].value_counts().values/ len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use 4 different models for training\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build functions\n",
    "\n",
    "we are going to build 3 functions :\n",
    "**loss** : to evaluate our models\n",
    "    precision\n",
    "    recall\n",
    "    f1\n",
    "    log_loss\n",
    "    accuracy_score\n",
    "    \n",
    "**train_eval_train** : to evaluate our models in the same data that we train it on .\n",
    "\n",
    "**train_eval_cross** : to evaluate our models using different data that we train the model on .\n",
    "\n",
    "StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**so you may ask why we don't just train our model and evaluate it without building this functions ?**\n",
    "actually you can do that,but mostly your model will not work good at beginning, so you need to change something about your data to improve your accuracy , by changing i mean data processing, and every step you will make, you should evaluate your model to see if it is improving or not, so to not do this step every time, this functions will make life easy as you go :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n",
    "\n",
    "def loss(y_true, y_pred, retu=False):\n",
    "    pre  = precision_score(y_true, y_pred)\n",
    "    rec  = recall_score(y_true, y_pred)\n",
    "    f1   = f1_score(y_true, y_pred)\n",
    "    loss = log_loss(y_true, y_pred)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    if retu:\n",
    "        return pre, rec, f1, loss, acc\n",
    "    else:\n",
    "        print('  pre: %.3f\\n  rec: %.3f\\n  f1: %.3f\\n  loss: %.3f\\n  acc: %.3f' % (pre, rec, f1, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_eval_train\n",
    "\n",
    "def train_eval_train(models, X, y):\n",
    "    for name, model in models.items():\n",
    "        print(name,':')\n",
    "        model.fit(X, y)\n",
    "        loss(y, model.predict(X))\n",
    "        print('-'*30)\n",
    "        \n",
    "train_eval_train(models, X_train, y_train)\n",
    "\n",
    "# we can see that best model is LogisticRegression at least for now, SVC is just memorizing the data so it is overfitting ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_eval_cross\n",
    "# in the next cell i will be explaining this function\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "def train_eval_cross(models, X, y, folds):\n",
    "    # we will change X & y to dataframe because we will use iloc (iloc don't work on numpy array)\n",
    "    X = pd.DataFrame(X) \n",
    "    y = pd.DataFrame(y)\n",
    "    idx = [' pre', ' rec', ' f1', ' loss', ' acc']\n",
    "    for name, model in models.items():\n",
    "        ls = []\n",
    "        print(name,':')\n",
    "\n",
    "        for train, test in folds.split(X, y):\n",
    "            model.fit(X.iloc[train], y.iloc[train]) \n",
    "            y_pred = model.predict(X.iloc[test]) \n",
    "            ls.append(loss(y.iloc[test], y_pred, retu=True))\n",
    "        print(pd.DataFrame(np.array(ls).mean(axis=0), index=idx)[0])  #[0] because we don't want to show the name of the column\n",
    "        print('-'*30)\n",
    "        \n",
    "train_eval_cross(models, X_train, y_train, skf)\n",
    "\n",
    "# ohhh, as i said SVC is just memorizing the data, and you can see that here DecisionTreeClassifier is better than LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some explanation of the above function\n",
    "\n",
    "x = []\n",
    "idx = [' pre', ' rec', ' f1', ' loss', ' acc']\n",
    "\n",
    "# we will use one model\n",
    "log = LogisticRegression()\n",
    "\n",
    "for train, test in skf.split(X_train, y_train):\n",
    "    log.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "    ls = loss(y_train.iloc[test], log.predict(X_train.iloc[test]), retu=True)\n",
    "    x.append(ls)\n",
    "    \n",
    "# thats what we get\n",
    "pd.DataFrame(x, columns=idx)\n",
    "\n",
    "# (column 0 represent the precision_score of the 10 folds)\n",
    "# (row 0 represent the (pre, rec, f1, loss, acc) for the first fold)\n",
    "# then we should find the mean of every column\n",
    "# pd.DataFrame(x, columns=idx).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Start to Improve Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ooh, we got it right for most of the features, as you can see we've say at the first of the kernel ,\n",
    "# that Credit_Histroy and Married etc, are good features, actually Credit_Histroy is the best .\n",
    "\n",
    "data_corr = pd.concat([X_train, y_train], axis=1)\n",
    "corr = data_corr.corr()\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(corr, annot=True);\n",
    "\n",
    "# here we got 58% similarity between LoanAmount & ApplicantIncome \n",
    "# and that may be bad for our model so we will see what we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try to make some operations on some features, here I just tried diffrent operations on diffrent features,\n",
    "# having experience in the field, and having knowledge about the data will also help\n",
    "\n",
    "X_train['new_col'] = X_train['CoapplicantIncome'] / X_train['ApplicantIncome']  \n",
    "X_train['new_col_2'] = X_train['LoanAmount'] * X_train['Loan_Amount_Term'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = pd.concat([X_train, y_train], axis=1)\n",
    "corr = data_corr.corr()\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(corr, annot=True);\n",
    "\n",
    "# new_col 0.03 , new_col_2, 0.047\n",
    "# not that much , but that will help us reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_cross(models, X_train, y_train, skf)\n",
    "\n",
    "# ok, SVC is improving, but LogisticRegression is overfitting\n",
    "# i wan't change nothing so we can see what will happen as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets take a look at the value counts of every label\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    print(X_train.iloc[:,i].value_counts(), end='\\n------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will work on the features that have varied values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_col_2\n",
    "\n",
    "# we can see we got right_skewed\n",
    "# we can solve this problem with very simple statistical teqniq , by taking the logarithm of all the values\n",
    "# because when data is normally distributed that will help improving our model\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "\n",
    "sns.distplot(X_train['new_col_2'], ax=ax[0], fit=norm)\n",
    "ax[0].set_title('new_col_2 before log')\n",
    "\n",
    "X_train['new_col_2'] = np.log(X_train['new_col_2'])  # logarithm of all the values\n",
    "\n",
    "sns.distplot(X_train['new_col_2'], ax=ax[1], fit=norm)\n",
    "ax[1].set_title('new_col_2 after log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will evaluate our models, and i will do that continuously ,so i don't need to mention that every time\n",
    "\n",
    "train_eval_cross(models, X_train, y_train, skf)\n",
    "\n",
    "# wooow our models improved really good by just doing the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_col\n",
    "\n",
    "# most of our data is 0 , so we will try to change other values to 1\n",
    "\n",
    "print('before:')\n",
    "print(X_train['new_col'].value_counts())\n",
    "\n",
    "X_train['new_col'] = [x if x==0 else 1 for x in X_train['new_col']]\n",
    "print('-'*50)\n",
    "print('\\nafter:')\n",
    "print(X_train['new_col'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_cross(models, X_train, y_train, skf)\n",
    "\n",
    "# ok we are improving our models as we go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_train.shape[1]):\n",
    "    print(X_train.iloc[:,i].value_counts(), end='\\n------------------------------------------------\\n')\n",
    "    \n",
    "# looks better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Outliers**\n",
    "there is different techniques to handle outliers, here we are going to use IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use boxplot to detect outliers\n",
    "\n",
    "sns.boxplot(X_train['new_col_2']);\n",
    "plt.title('new_col_2 outliers', fontsize=15);\n",
    "plt.xlabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1  # this number is hyper parameter , as much as you reduce it, as much as you remove more points\n",
    "                 # you can just try different values the deafult value is (1.5) it works good for most cases\n",
    "                 # but be careful, you don't want to try a small number because you may loss some important information from the data .\n",
    "                 # that's why I was surprised when 0.1 gived me the best result\n",
    "            \n",
    "new_col_2_out = X_train['new_col_2']\n",
    "q25, q75 = np.percentile(new_col_2_out, 25), np.percentile(new_col_2_out, 75) # Q25, Q75\n",
    "print('Quartile 25: {} , Quartile 75: {}'.format(q25, q75))\n",
    "\n",
    "iqr = q75 - q25\n",
    "print('iqr: {}'.format(iqr))\n",
    "\n",
    "cut = iqr * threshold\n",
    "lower, upper = q25 - cut, q75 + cut\n",
    "print('Cut Off: {}'.format(cut))\n",
    "print('Lower: {}'.format(lower))\n",
    "print('Upper: {}'.format(upper))\n",
    "\n",
    "outliers = [x for x in new_col_2_out if x < lower or x > upper]\n",
    "print('Nubers of Outliers: {}'.format(len(outliers)))\n",
    "print('outliers:{}'.format(outliers))\n",
    "\n",
    "data_outliers = pd.concat([X_train, y_train], axis=1)\n",
    "print('\\nlen X_train before dropping the outliers', len(data_outliers))\n",
    "data_outliers = data_outliers.drop(data_outliers[(data_outliers['new_col_2'] > upper) | (data_outliers['new_col_2'] < lower)].index)\n",
    "\n",
    "print('len X_train before dropping the outliers', len(data_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_outliers.drop('Loan_Status', axis=1)\n",
    "y_train = data_outliers['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(X_train['new_col_2']);\n",
    "plt.title('new_col_2 without outliers', fontsize=15);\n",
    "plt.xlabel('');\n",
    "\n",
    "# good :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_cross(models, X_train, y_train, skf)\n",
    "\n",
    "# know we got 94.1 for precision & 53.5 for recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self_Employed got really bad corr (-0.00061) , let's try remove it and see what will happen\n",
    "\n",
    "data_corr = pd.concat([X_train, y_train], axis=1)\n",
    "corr = data_corr.corr()\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(corr, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.drop(['Self_Employed'], axis=1, inplace=True)\n",
    "\n",
    "train_eval_cross(models, X_train, y_train, skf)\n",
    "\n",
    "# looks like Self_Employed is not important\n",
    "# KNeighborsClassifier improved\n",
    "\n",
    "# droping all the features Except for Credit_History actually improved KNeighborsClassifier and didn't change anything in other models\n",
    "# so you can try it by you self\n",
    "# but don't forget to do that on testing data too\n",
    "\n",
    "#X_train.drop(['Self_Employed','Dependents', 'new_col_2', 'Education', 'Gender', 'Property_Area','Married', 'new_col'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = pd.concat([X_train, y_train], axis=1)\n",
    "corr = data_corr.corr()\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(corr, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the models on Test_data\n",
    "here we will just repeat what we did in training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "\n",
    "X_test_new['new_col'] = X_test_new['CoapplicantIncome'] / X_test_new['ApplicantIncome']  \n",
    "X_test_new['new_col_2'] = X_test_new['LoanAmount'] * X_test_new['Loan_Amount_Term']\n",
    "X_test_new.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)\n",
    "\n",
    "X_test_new['new_col_2'] = np.log(X_test_new['new_col_2'])\n",
    "\n",
    "X_test_new['new_col'] = [x if x==0 else 1 for x in X_test_new['new_col']]\n",
    "\n",
    "#X_test_new.drop(['Self_Employed'], axis=1, inplace=True)\n",
    "\n",
    "# drop all the features Except for Credit_History\n",
    "#X_test_new.drop(['Self_Employed','Dependents', 'new_col_2', 'Education', 'Gender', 'Property_Area','Married', 'new_col'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,model in models.items():\n",
    "    print(name, end=':\\n')\n",
    "    loss(y_test, model.predict(X_test_new))\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conclusion:\n",
    "\n",
    "what ever we do, our recall score will not improving , maybe because we don't have a good amount of data, so I think if we got more data and we try more complex models our accuracy will improve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
